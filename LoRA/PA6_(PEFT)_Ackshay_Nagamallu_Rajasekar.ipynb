{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "efc30363",
      "metadata": {
        "id": "efc30363"
      },
      "source": [
        "# Fine-Tuning LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78bbda16",
      "metadata": {
        "id": "78bbda16"
      },
      "source": [
        "In this exercise, you will fine-tune the [Flan-T5](https://huggingface.co/docs/transformers/model_doc/flan-t5) model for enhanced dialogue summarization. You will first explore a full fine-tuning approach and evaluate the results with ROUGE metrics. Then you will perform Parameter-Efficient Fine-Tuning (PEFT), evaluate the resulting model and see that the benefits of PEFT outweigh the slightly-lower performance metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae38df4f",
      "metadata": {
        "id": "ae38df4f"
      },
      "source": [
        "## 1. Set up Dependencies and Load Dataset and LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cfaa9a71",
      "metadata": {
        "id": "cfaa9a71"
      },
      "outputs": [],
      "source": [
        "!pip install datasets evaluate rouge_score peft -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "7bfc5e61",
      "metadata": {
        "id": "7bfc5e61"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "import evaluate\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from transformers import Seq2SeqTrainingArguments, DataCollatorForSeq2Seq, Seq2SeqTrainer\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9e0022db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e0022db",
        "outputId": "05642d49-3746-4724-ae78-d54927ce962f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset('knkarthick/dialogsum')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "829a483e",
      "metadata": {
        "id": "829a483e"
      },
      "source": [
        "Load the pre-trained [Flan-T5 model](https://huggingface.co/docs/transformers/model_doc/flan-t5) and its tokenizer from HuggingFace. Notice that you will be using the [small version](https://huggingface.co/google/flan-t5-base) of Flan-T5. Setting `torch_dtype=torch.bfloat16` specifies the data type to be used by this model, which can reduce GPU memory usage since `bfloat16` uses half as much memory per number compared to `float32`, the default precision for most models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3b475615",
      "metadata": {
        "id": "3b475615"
      },
      "outputs": [],
      "source": [
        "model_name = 'google/flan-t5-base'\n",
        "\n",
        "original_model = AutoModelForSeq2SeqLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "404331c9",
      "metadata": {
        "id": "404331c9"
      },
      "source": [
        "## 2. Test the Model with Zero-Shot Inferencing\n",
        "\n",
        "Test the model with zero-shot inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "903afec6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "903afec6",
        "outputId": "f4718ba0-6226-4240-87a1-cf913feed0b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "#Person1#: I don't know how to adjust my life. Would you give me a piece of advice?\n",
            "#Person2#: You look a bit pale, don't you?\n",
            "#Person1#: Yes, I can't sleep well every night.\n",
            "#Person2#: You should get plenty of sleep.\n",
            "#Person1#: I drink a lot of wine.\n",
            "#Person2#: If I were you, I wouldn't drink too much.\n",
            "#Person1#: I often feel so tired.\n",
            "#Person2#: You better do some exercise every morning.\n",
            "#Person1#: I sometimes find the shadow of death in front of me.\n",
            "#Person2#: Why do you worry about your future? You're very young, and you'll make great contribution to the world. I hope you take my advice.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person1# wants to adjust #Person1#'s life and #Person2# suggests #Person1# be positive and stay healthy.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "MODEL GENERATION - ZERO SHOT:\n",
            "#Person1#: I'm not sure how to adjust my life.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "index = 42\n",
        "dash_line = '-' * 100\n",
        "\n",
        "dialogue = dataset['test'][index]['dialogue']\n",
        "summary = dataset['test'][index]['summary']\n",
        "\n",
        "prompt = f\"Summarize the following conversation.\\n{dialogue}\\nSummary:\\n\"\n",
        "inputs = tokenizer(prompt, return_tensors='pt')\n",
        "output = original_model.generate(inputs['input_ids'], max_new_tokens=50)[0]\n",
        "original_model_summary = tokenizer.decode(output, skip_special_tokens=True)\n",
        "\n",
        "print(dash_line)\n",
        "print(f'INPUT PROMPT:\\n{dialogue}')\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n",
        "print(dash_line)\n",
        "print(f'MODEL GENERATION - ZERO SHOT:\\n{original_model_summary}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hqKrbmjxvXhn",
      "metadata": {
        "id": "hqKrbmjxvXhn"
      },
      "source": [
        "You can see that the model struggles to summarize the dialogue compared to the baseline summary, and simply repeats the first sentence from the dialogue."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39269c1c",
      "metadata": {
        "id": "39269c1c"
      },
      "source": [
        "## 3. Perform Full Fine-Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebb795b4",
      "metadata": {
        "id": "ebb795b4"
      },
      "source": [
        "### 3.1 Preprocess the Dataset\n",
        "\n",
        "You need to convert the dialog-summary (prompt-response) pairs into explicit instructions for the LLM. Prepend an instruction to the start of the dialog with `Summarize the following conversation.`, and to the start of the summary with `Summary:` as follows:\n",
        "\n",
        "Training prompt (dialogue):\n",
        "```\n",
        "Summarize the following conversation.\n",
        "Alice: This is her part of the conversation.\n",
        "Bob: This is his part of the conversation.    \n",
        "Summary:\n",
        "```\n",
        "\n",
        "Training response (summary):\n",
        "```\n",
        "Both Alice and Bob participated in the conversation.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EVGHecAnv8s0",
      "metadata": {
        "id": "EVGHecAnv8s0"
      },
      "source": [
        "**Exercise**: Write a function to tokenize a batch of examples from the dialogue dataset. The function should concatentate the dialogues with the predefined prompt, tokenize them along with their summaries, and define the tokenized summaries as the labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "T6bMPv3ZK3UD",
      "metadata": {
        "id": "T6bMPv3ZK3UD"
      },
      "outputs": [],
      "source": [
        "def tokenize(examples):\n",
        "    ### WRITE YOUR CODE HERE\n",
        "      inputs = [f\"Summarize the following conversation.\\n{d}\\nSummary:\\n\" for d in examples[\"dialogue\"]]\n",
        "      model_inputs = tokenizer(\n",
        "          inputs,\n",
        "          max_length=512,\n",
        "          truncation=True,\n",
        "          padding = 'max_length'\n",
        "      )\n",
        "      with tokenizer.as_target_tokenizer():\n",
        "        targets = tokenizer(\n",
        "            examples[\"summary\"],\n",
        "            max_length=128,\n",
        "            truncation=True,\n",
        "            padding = 'max_length'\n",
        "        )\n",
        "      model_inputs[\"labels\"] = targets[\"input_ids\"]\n",
        "      return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "JPtVA3XzK5OG",
      "metadata": {
        "id": "JPtVA3XzK5OG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169,
          "referenced_widgets": [
            "5532a6f9ef7c4c64860256251072932e",
            "9d6ce7dab7dd45dea2466a897a8a14e2",
            "a4086d034765449db57b24ef1c630e03",
            "74f45dc6318540eb8a3d62c7ad47f569",
            "d70194811cb94588a962dafddfb610a1",
            "b3f3c1cb97fe4f3a9d1a7b3fe44b8e67",
            "f0285d9dbe7240f48c35e3d2a4bd00cb",
            "52bebf69b1584849b40749c5f4cb28ed",
            "afc28a291ddf4193b0f34d75e473857f",
            "754a649c43cf4e9285c20ed715306258",
            "ed7c636fb5fb4f2a8c73745cf33d5323",
            "26958cdd43b44b4180d9db5f0d8fd00f",
            "e9768ca1de2a4221bed18080fa944eb4",
            "5cf8f637718946698a9ad1c37f84045a",
            "b9fea0370e1c4c6a8f5ce8f59e152b0d",
            "664fe8697cd64c1d935aee75efbeb7b7",
            "f5b8459290d64dcc80ae0d15585d9df8",
            "bdb1c5af6b8e49bd8b61addacf0b2de2",
            "a71b8fe4930240a58910040427543ad5",
            "e847347474b744afaf3e94e2e4e7df03",
            "fb9affbefa1b4fe48aaba0abe203c518",
            "9672a2e06d264c28a1dc755496c4b41f",
            "e87b4377515e4891bb70ae1bfd5d0a69",
            "203781307b194b10b08f6ac1a72d9c1f",
            "afc1c67ef78040c58e48be5949e0c563",
            "5cddd283ec0b41eb947ef950fc8095b3",
            "939c622fdf0741b39cf68d8cf42b61b0",
            "87d38c2a23b242c18153203d076d60f3",
            "f433e69cca824d5d830012d775d0fd57",
            "7d8a3a4ab248417e996370faba9af58b",
            "9e47f089bc174e2fa9fc5d0bcd42a2d8",
            "d3433db2503d418a847d3b3bdf138eb6",
            "3d4c58b99bcb45ceb0bfb5839389f2a7"
          ]
        },
        "outputId": "dbe8e6b1-f0f3-4d6e-e031-00e1a9afcc01"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/12460 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5532a6f9ef7c4c64860256251072932e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4006: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26958cdd43b44b4180d9db5f0d8fd00f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e87b4377515e4891bb70ae1bfd5d0a69"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenized_dataset = dataset.map(tokenize, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "101bb5da",
      "metadata": {
        "id": "101bb5da"
      },
      "source": [
        "### 3.2 Fine-Tune the Model\n",
        "\n",
        "**Exercise**: Utilize the Hugging Face Trainer API for training the model on the preprocessed dataset. Define the training arguments, a data collator, and create a `Seq2SeqTrainer` instance. Train the model for one epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1ad8f449",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ad8f449",
        "outputId": "8744a875-b7fe-4ee9-b095-69e40e759aa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-33067838.py:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        }
      ],
      "source": [
        "### WRITE YOUR CODE HERE\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./flan-t5-base-dialogsum-checkpoint\",\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate=5e-5,\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=50,\n",
        "    predict_with_generate=True,\n",
        "    report_to=\"none\",\n",
        "    bf16=torch.cuda.is_available(),\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=original_model)\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=original_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset['validation'],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "070b86e4",
      "metadata": {
        "id": "070b86e4"
      },
      "source": [
        "Training a fully fine-tuned version of the model should take about 10 minutes on a Google Colab GPU machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "22e44303",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "22e44303",
        "outputId": "c775495b-a0ef-44c7-c6a7-8c9530f254ec"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='390' max='390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [390/390 07:38, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>38.855100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>38.687700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>36.906300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>33.329000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>26.534100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>12.444900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>4.049600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=390, training_loss=24.822152514335436, metrics={'train_runtime': 459.9277, 'train_samples_per_second': 27.091, 'train_steps_per_second': 0.848, 'total_flos': 8532076611502080.0, 'train_loss': 24.822152514335436, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcOg9qQ_9M5M",
      "metadata": {
        "id": "bcOg9qQ_9M5M"
      },
      "source": [
        "Save the model to a local folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "klGQxAQf7prf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klGQxAQf7prf",
        "outputId": "1b4bca73-2ba4-42b6-b599-62aa44d5da65"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./flan-t5-base-dialogsum-checkpoint/tokenizer_config.json',\n",
              " './flan-t5-base-dialogsum-checkpoint/special_tokens_map.json',\n",
              " './flan-t5-base-dialogsum-checkpoint/spiece.model',\n",
              " './flan-t5-base-dialogsum-checkpoint/added_tokens.json',\n",
              " './flan-t5-base-dialogsum-checkpoint/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "model_path = './flan-t5-base-dialogsum-checkpoint'\n",
        "\n",
        "original_model.save_pretrained(model_path)\n",
        "tokenizer.save_pretrained(model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "814042dd",
      "metadata": {
        "id": "814042dd"
      },
      "source": [
        "Create an instance of the `AutoModelForSeq2SeqLM` class for the instruct model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "d98f4126",
      "metadata": {
        "id": "d98f4126"
      },
      "outputs": [],
      "source": [
        "instruct_model = AutoModelForSeq2SeqLM.from_pretrained('./flan-t5-base-dialogsum-checkpoint',\n",
        "                                                       torch_dtype=torch.bfloat16)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dK1EsTihBrHJ",
      "metadata": {
        "id": "dK1EsTihBrHJ"
      },
      "source": [
        "Reload the original Flan-T5-base model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "mdS7JS6PBpAh",
      "metadata": {
        "id": "mdS7JS6PBpAh"
      },
      "outputs": [],
      "source": [
        "original_model = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-base', torch_dtype=torch.bfloat16)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "964bc7e3",
      "metadata": {
        "id": "964bc7e3"
      },
      "source": [
        "### 3.3 Evaluate the Model Qualitatively (Human Evaluation)\n",
        "\n",
        "**Exercise**: Make inferences for the same example as in Section 2, using the original model and the fully fine-tuned model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "e10df481",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e10df481",
        "outputId": "ecd43234-bfc7-4393-d31c-38cb5d012db4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "#Person1#: Is anybody in?\n",
            "#Person2#: How can I help you?\n",
            "#Person1#: I have a headache.\n",
            "#Person2#: Let me take your temperature with a thermometer.\n",
            "#Person1#: OK.\n",
            "#Person2#: I think you have a small fever.\n",
            "#Person1#: I thought so. I felt dizzy this morning.\n",
            "#Person2#: You should've called in sick! Next time, have either of your parents call the school office.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person2# checks #Person1#'s physical condition and finds #Person1# has a fever.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "ORIGINAL MODEL (zero-shot) SUMMARY:\n",
            "#Person1#: I have a headache. #Person2#: I think you have a small fever.\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "INSTRUCT MODEL (full FT) SUMMARY:\n",
            "#Person2# asks #Person1# to take #Person1#'s temperature.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### WRITE YOUR CODE HERE\n",
        "index = 56\n",
        "dash_line = '-' * 100\n",
        "\n",
        "dialogue = dataset['test'][index]['dialogue']\n",
        "summary = dataset['test'][index]['summary']\n",
        "\n",
        "prompt = f\"Summarize the following conversation.\\n{dialogue}\\nSummary:\\n\"\n",
        "inputs = tokenizer(prompt, return_tensors='pt')\n",
        "\n",
        "orig_ids = original_model.generate(inputs['input_ids'], max_new_tokens=50)[0]\n",
        "original_model_summary = tokenizer.decode(orig_ids, skip_special_tokens=True)\n",
        "\n",
        "instr_ids = instruct_model.generate(inputs['input_ids'], max_new_tokens=50)[0]\n",
        "instruct_model_summary = tokenizer.decode(instr_ids, skip_special_tokens=True)\n",
        "\n",
        "print(dash_line)\n",
        "print(f'INPUT PROMPT:\\n{dialogue}')\n",
        "print(dash_line)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{summary}')\n",
        "print(dash_line)\n",
        "print(f'ORIGINAL MODEL (zero-shot) SUMMARY:\\n{original_model_summary}\\n')\n",
        "print(dash_line)\n",
        "print(f'INSTRUCT MODEL (full FT) SUMMARY:\\n{instruct_model_summary}\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c65474b3",
      "metadata": {
        "id": "c65474b3"
      },
      "source": [
        "The fine-tuned model is able to create a much better summary of the dialogue compared to the original model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b1ffbd2",
      "metadata": {
        "id": "4b1ffbd2"
      },
      "source": [
        "### 3.4 Evaluate the Model Quantitatively (with ROUGE Metric)\n",
        "\n",
        "The [ROUGE metric](https://en.wikipedia.org/wiki/ROUGE_(metric)) helps quantify the validity of summarizations produced by models. It compares summarizations to a \"baseline\" summary which is usually created by a human. While not perfect, it does indicate the overall increase in summarization effectiveness that we have accomplished by fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "cf2a480b",
      "metadata": {
        "id": "cf2a480b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "0df2b2052f4c48a1b71e82bdb11c49d7",
            "ed5cd674bd0a4fccab9c1a32b66b631d",
            "c6368f64fc6d4dd5a39731d49ee46bf6",
            "7131be181fec4e4581bf8a27c8d62cf1",
            "bb7e510d39a74009bca93a2d67746ca1",
            "5f42e0ee80fa487badb6f6f319497c65",
            "6fd074f5dec84734b2a89ce3e1f25d03",
            "051cb2fc4508453b97d1ce4e14c689a0",
            "77564d3aaf5a4e60a3250b06f9583871",
            "f14419121e114de98470658863061b4b",
            "0e58fcf093b64955b86a6cc5923613e8"
          ]
        },
        "outputId": "42d4dd96-6081-4287-9d2c-d2f3a193f870"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0df2b2052f4c48a1b71e82bdb11c49d7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "rouge = evaluate.load('rouge')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "in2SYXRfCNWA",
      "metadata": {
        "id": "in2SYXRfCNWA"
      },
      "source": [
        "**Exercise**: Generate the outputs for a sample of the test set with the fine-tuned model (use only the first 10 dialogues and summaries to save time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "pAOnB6lFCOUw",
      "metadata": {
        "id": "pAOnB6lFCOUw"
      },
      "outputs": [],
      "source": [
        "### WRITE YOUR CODE HERE\n",
        "num_examples = 10\n",
        "test_dialogues = dataset['test']['dialogue'][:num_examples]\n",
        "human_baseline_summaries = dataset['test']['summary'][:num_examples]\n",
        "\n",
        "original_model_summaries = []\n",
        "instruct_model_summaries = []\n",
        "\n",
        "for dlg in test_dialogues:\n",
        "    text_input = f\"Summarize the following conversation.\\n{dlg}\\nSummary:\\n\"\n",
        "    tokens = tokenizer(text_input, return_tensors='pt')\n",
        "\n",
        "    orig_result = original_model.generate(tokens['input_ids'], max_new_tokens=50)[0]\n",
        "    original_model_summaries.append(tokenizer.decode(orig_result, skip_special_tokens=True))\n",
        "\n",
        "    inst_result = instruct_model.generate(tokens['input_ids'], max_new_tokens=50)[0]\n",
        "    instruct_model_summaries.append(tokenizer.decode(inst_result, skip_special_tokens=True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4a019aaa",
      "metadata": {
        "id": "4a019aaa"
      },
      "source": [
        "Evaluate the models computing ROUGE metrics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "d77847c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d77847c0",
        "outputId": "0bdfa34a-3c82-4955-f5d8-d967a9f7ceae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL MODEL:\n",
            "{'rouge1': np.float64(0.22420174087325248), 'rouge2': np.float64(0.09872463768115944), 'rougeL': np.float64(0.2089424816139932), 'rougeLsum': np.float64(0.21333914728682168)}\n",
            "INSTRUCT MODEL:\n",
            "{'rouge1': np.float64(0.3517586339059473), 'rouge2': np.float64(0.13560846560846562), 'rougeL': np.float64(0.30331246693203817), 'rougeLsum': np.float64(0.3050757898077988)}\n"
          ]
        }
      ],
      "source": [
        "original_model_results = rouge.compute(\n",
        "    predictions=original_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(original_model_summaries)]\n",
        ")\n",
        "\n",
        "instruct_model_results = rouge.compute(\n",
        "    predictions=instruct_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(instruct_model_summaries)]\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "print('INSTRUCT MODEL:')\n",
        "print(instruct_model_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c44701b",
      "metadata": {
        "id": "1c44701b"
      },
      "source": [
        "The results show substantial improvement in all ROUGE metrics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "e2d1a51a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2d1a51a",
        "outputId": "10462839-4507-4a1c-d46b-4b0a3be03f66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absolute percentage improvement of the instruct model over the original model:\n",
            "rouge1: 12.76%\n",
            "rouge2: 3.69%\n",
            "rougeL: 9.44%\n",
            "rougeLsum: 9.17%\n"
          ]
        }
      ],
      "source": [
        "print(\"Absolute percentage improvement of the instruct model over the original model:\")\n",
        "\n",
        "for key in instruct_model_results:\n",
        "    improvement = instruct_model_results[key] - original_model_results[key]\n",
        "    print(f'{key}: {improvement*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Iq72DeUafKOL",
      "metadata": {
        "id": "Iq72DeUafKOL"
      },
      "source": [
        "## 4. Perform Parameter Efficient Fine-Tuning (PEFT)\n",
        "\n",
        "Now, let's perform **Parameter Efficient Fine-Tuning (PEFT)** instead of \"full fine-tuning\" as you did above. PEFT is a form of instruction fine-tuning that is much more efficient than full fine-tuning, with comparable evaluation results as you will see soon.\n",
        "\n",
        "One of the most popular PEFT methods is **Low-Rank Adaptation (LoRA)**, which  introduces low-rank matrices to adapt the LLM with minimal additional parameters. In most cases, when someone says PEFT, they typically mean LoRA.  After fine-tuning for a specific task with LoRA, the result is that the original LLM remains unchanged and a newly-trained \"LoRA adapter\" emerges. This LoRA adapter is much smaller than the original LLM - on the order of a single-digit % of the original LLM size (MBs vs GBs).  \n",
        "\n",
        "At inference time, the LoRA adapter is reunited and combined with its original LLM to serve the inference request. The benefit is that many LoRA adapters can re-use the original LLM which reduces overall memory requirements when serving multiple tasks and use cases."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jjMz_LZrfRKN",
      "metadata": {
        "id": "jjMz_LZrfRKN"
      },
      "source": [
        "### 4.1 Setup the LoRA model for Fine-Tuning\n",
        "\n",
        "You first need to define the configuration of the LoRA model. Have a look at the configuration below. The key configuration element to adjust is the rank (`r`) of the adapter, which influences its capacity and complexity. Experiment with various ranks, such as 8, 16, or 32, and see how they affect the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "c52eb8bf",
      "metadata": {
        "id": "c52eb8bf"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, TaskType, get_peft_model\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "    r=32,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lrxAQD2tflZA",
      "metadata": {
        "id": "lrxAQD2tflZA"
      },
      "source": [
        "Add LoRA adapter layers/parameters to the original LLM to be trained:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "1IHrKzPnfL-n",
      "metadata": {
        "id": "1IHrKzPnfL-n"
      },
      "outputs": [],
      "source": [
        "peft_model = get_peft_model(original_model, lora_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b4ae88c",
      "metadata": {
        "id": "3b4ae88c"
      },
      "source": [
        "The number of trainable model parameters in the LoRA model is:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "e35a2022",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e35a2022",
        "outputId": "30a7cfc8-10c9-4c57-a47c-6f5ec8f0769c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 3,538,944 || all params: 251,116,800 || trainable%: 1.4093\n"
          ]
        }
      ],
      "source": [
        "peft_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zpLzokfYfo_m",
      "metadata": {
        "id": "zpLzokfYfo_m"
      },
      "source": [
        "### 4.2 Train the LoRA Adapter\n",
        "\n",
        "**Exercise**: Define training arguments and create a `Seq2SeqTrainer` instance for the LoRA model. Use a higher learning rate than full fine-tuning (e.g., `1e-3`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "5oEIIiIofrC8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oEIIiIofrC8",
        "outputId": "99495a83-9cad-4376-e809-33be1765ee64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-568516899.py:18: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  peft_trainer = Seq2SeqTrainer(\n"
          ]
        }
      ],
      "source": [
        "### WRITE YOUR CODE HERE\n",
        "peft_training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./flan-t5-base-dialogsum-lora\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    gradient_accumulation_steps=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    save_strategy='no',\n",
        "    predict_with_generate=True,\n",
        "    learning_rate=1e-3,\n",
        "    fp16=False,\n",
        "    report_to='none'\n",
        ")\n",
        "\n",
        "peft_trainer = Seq2SeqTrainer(\n",
        "    model=peft_model,\n",
        "    args=peft_training_args,\n",
        "    train_dataset=tokenized_dataset['train'],\n",
        "    eval_dataset=tokenized_dataset['validation'],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "H_2jryxZgMdR",
      "metadata": {
        "id": "H_2jryxZgMdR"
      },
      "source": [
        "Train the PEFT adapter. Training should take about 6 minutes on a Google Colab GPU machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "f0d7T_P1gNlP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "f0d7T_P1gNlP",
        "outputId": "64846c61-6280-4d63-d1fe-5087fbf2553e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='390' max='390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [390/390 09:36, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>39.797900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>40.254500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>37.973600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>36.292000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>32.384100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>27.365300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>22.526200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>17.410400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>10.131200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>4.865800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>4.019500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>3.788500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>3.496900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>3.011100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>2.438900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>160</td>\n",
              "      <td>1.801100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>170</td>\n",
              "      <td>1.295000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>1.006300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>190</td>\n",
              "      <td>0.816100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.740000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>0.676000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>220</td>\n",
              "      <td>0.608100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>230</td>\n",
              "      <td>0.596400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.558900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.545300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>260</td>\n",
              "      <td>0.546200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>0.532300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>280</td>\n",
              "      <td>0.497300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>290</td>\n",
              "      <td>0.513400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.532000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>310</td>\n",
              "      <td>0.510100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>320</td>\n",
              "      <td>0.467500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>0.465400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>340</td>\n",
              "      <td>0.491300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.459400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.469900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>370</td>\n",
              "      <td>0.463700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>380</td>\n",
              "      <td>0.466300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>390</td>\n",
              "      <td>0.463300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=390, training_loss=7.7250482277992445, metrics={'train_runtime': 578.4609, 'train_samples_per_second': 21.54, 'train_steps_per_second': 0.674, 'total_flos': 8667537195663360.0, 'train_loss': 7.7250482277992445, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "peft_trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vJ_h6KU2gcUf",
      "metadata": {
        "id": "vJ_h6KU2gcUf"
      },
      "source": [
        "Save the model to a local folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "7T9fwZ0NhOKC",
      "metadata": {
        "id": "7T9fwZ0NhOKC"
      },
      "outputs": [],
      "source": [
        "peft_model.save_pretrained('./flan-t5-base-dialogsum-lora')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KmqvrFOrhVby",
      "metadata": {
        "id": "KmqvrFOrhVby"
      },
      "source": [
        "Load the PEFT model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "Wit_mz3Vgh-V",
      "metadata": {
        "id": "Wit_mz3Vgh-V"
      },
      "outputs": [],
      "source": [
        "from peft import AutoPeftModelForSeq2SeqLM\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "peft_model = AutoModelForSeq2SeqLM.from_pretrained('./flan-t5-base-dialogsum-lora')\n",
        "tokenizer = AutoTokenizer.from_pretrained('google/flan-t5-base')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dogDPmBBkuya",
      "metadata": {
        "id": "dogDPmBBkuya"
      },
      "source": [
        "Reload the original Flan-T5-base model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "EFur6v7nkItQ",
      "metadata": {
        "id": "EFur6v7nkItQ"
      },
      "outputs": [],
      "source": [
        "original_model = AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-base', torch_dtype=torch.bfloat16)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-AHhrS2lheOH",
      "metadata": {
        "id": "-AHhrS2lheOH"
      },
      "source": [
        "### 4.3 Evaluate the Model Qualitatively (Human Evaluation)\n",
        "\n",
        "**Exercise**: Make inferences for the same example as in Sections 2 and 3, using the original model, the fully fine-tuned model and the PEFT model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "yGFEKSwAhXr6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGFEKSwAhXr6",
        "outputId": "983198fc-03b9-4226-ecc4-b90ae88acb8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "INPUT PROMPT:\n",
            "#Person1#: Is anybody in?\n",
            "#Person2#: How can I help you?\n",
            "#Person1#: I have a headache.\n",
            "#Person2#: Let me take your temperature with a thermometer.\n",
            "#Person1#: OK.\n",
            "#Person2#: I think you have a small fever.\n",
            "#Person1#: I thought so. I felt dizzy this morning.\n",
            "#Person2#: You should've called in sick! Next time, have either of your parents call the school office.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "BASELINE HUMAN SUMMARY:\n",
            "#Person2# checks #Person1#'s physical condition and finds #Person1# has a fever.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "ORIGINAL MODEL SUMMARY:\n",
            "#Person1#: I have a headache. #Person2#: I think you have a small fever.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "INSTRUCT MODEL SUMMARY:\n",
            "#Person2# asks #Person1# to take #Person1#'s temperature.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "PEFT MODEL SUMMARY:\n",
            "#Person1# asks #Person2# to take #Person1#'s temperature with a thermometer. #Person1# thinks #Person1# has a small fever.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### WRITE YOUR CODE HERE\n",
        "test_idx = 56\n",
        "line_break = '-' * 100\n",
        "\n",
        "conversation = dataset['test'][test_idx]['dialogue']\n",
        "reference_summary = dataset['test'][test_idx]['summary']\n",
        "\n",
        "prompt_text = f\"Summarize the following conversation.\\n{conversation}\\nSummary:\\n\"\n",
        "encoded_input = tokenizer(prompt_text, return_tensors='pt')\n",
        "\n",
        "baseline_out = original_model.generate(encoded_input['input_ids'], max_new_tokens=50)[0]\n",
        "original_model_summary = tokenizer.decode(baseline_out, skip_special_tokens=True)\n",
        "\n",
        "finetuned_out = instruct_model.generate(encoded_input['input_ids'], max_new_tokens=50)[0]\n",
        "instruct_model_summary = tokenizer.decode(finetuned_out, skip_special_tokens=True)\n",
        "\n",
        "peft_out = peft_model.generate(encoded_input['input_ids'], max_new_tokens=50)[0]\n",
        "peft_model_summary = tokenizer.decode(peft_out, skip_special_tokens=True)\n",
        "\n",
        "print(line_break)\n",
        "print(f'INPUT PROMPT:\\n{conversation}')\n",
        "print(line_break)\n",
        "print(f'BASELINE HUMAN SUMMARY:\\n{reference_summary}')\n",
        "print(line_break)\n",
        "print(f'ORIGINAL MODEL SUMMARY:\\n{original_model_summary}')\n",
        "print(line_break)\n",
        "print(f'INSTRUCT MODEL SUMMARY:\\n{instruct_model_summary}')\n",
        "print(line_break)\n",
        "print(f'PEFT MODEL SUMMARY:\\n{peft_model_summary}\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YzNd3ptflWeS",
      "metadata": {
        "id": "YzNd3ptflWeS"
      },
      "source": [
        "### 4.4 Evaluate the Model Quantitatively (with ROUGE Metric)\n",
        "\n",
        "**Exercise**: Generate the outputs for a sample of the test set with the PEFT model (use only the first 10 dialogues and summaries to save time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "lkDE0mtrkD1K",
      "metadata": {
        "id": "lkDE0mtrkD1K"
      },
      "outputs": [],
      "source": [
        "### WRITE YOUR CODE HERE\n",
        "n_samples = 10\n",
        "eval_dialogues = dataset['test']['dialogue'][:n_samples]\n",
        "human_baseline_summaries = dataset['test']['summary'][:n_samples]\n",
        "\n",
        "original_model_summaries = []\n",
        "instruct_model_summaries = []\n",
        "peft_model_summaries = []\n",
        "\n",
        "for conversation_text in eval_dialogues:\n",
        "    formatted_prompt = f\"Summarize the following conversation.\\n{conversation_text}\\nSummary:\\n\"\n",
        "    input_ids = tokenizer(formatted_prompt, return_tensors='pt')\n",
        "\n",
        "    baseline_gen = original_model.generate(input_ids['input_ids'], max_new_tokens=50)[0]\n",
        "    original_model_summaries.append(tokenizer.decode(baseline_gen, skip_special_tokens=True))\n",
        "\n",
        "    finetuned_gen = instruct_model.generate(input_ids['input_ids'], max_new_tokens=50)[0]\n",
        "    instruct_model_summaries.append(tokenizer.decode(finetuned_gen, skip_special_tokens=True))\n",
        "\n",
        "    peft_gen = peft_model.generate(input_ids['input_ids'], max_new_tokens=50)[0]\n",
        "    peft_model_summaries.append(tokenizer.decode(peft_gen, skip_special_tokens=True))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TF6MuatKmFQz",
      "metadata": {
        "id": "TF6MuatKmFQz"
      },
      "source": [
        "Compute ROUGE score for this subset of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "bZmMVyDYmCDF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZmMVyDYmCDF",
        "outputId": "e372e4e8-7bc5-4582-de58-0b593f90769c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL MODEL:\n",
            "{'rouge1': np.float64(0.22420174087325248), 'rouge2': np.float64(0.09872463768115944), 'rougeL': np.float64(0.2089424816139932), 'rougeLsum': np.float64(0.21333914728682168)}\n",
            "INSTRUCT MODEL:\n",
            "{'rouge1': np.float64(0.3517586339059473), 'rouge2': np.float64(0.13560846560846562), 'rougeL': np.float64(0.30331246693203817), 'rougeLsum': np.float64(0.3050757898077988)}\n",
            "PEFT MODEL:\n",
            "{'rouge1': np.float64(0.3798405725048174), 'rouge2': np.float64(0.12038713332191245), 'rougeL': np.float64(0.29900923638504723), 'rougeLsum': np.float64(0.30010104805388926)}\n"
          ]
        }
      ],
      "source": [
        "original_model_results = rouge.compute(\n",
        "    predictions=original_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(original_model_summaries)],\n",
        ")\n",
        "\n",
        "instruct_model_results = rouge.compute(\n",
        "    predictions=instruct_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(instruct_model_summaries)],\n",
        ")\n",
        "\n",
        "peft_model_results = rouge.compute(\n",
        "    predictions=peft_model_summaries,\n",
        "    references=human_baseline_summaries[0:len(peft_model_summaries)],\n",
        ")\n",
        "\n",
        "print('ORIGINAL MODEL:')\n",
        "print(original_model_results)\n",
        "print('INSTRUCT MODEL:')\n",
        "print(instruct_model_results)\n",
        "print('PEFT MODEL:')\n",
        "print(peft_model_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NViojzFXmRn1",
      "metadata": {
        "id": "NViojzFXmRn1"
      },
      "source": [
        "Notice, that PEFT model results are not too bad, while the training process was much easier!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "C5CmTgHxmZBS",
      "metadata": {
        "id": "C5CmTgHxmZBS"
      },
      "source": [
        "Calculate the improvement of PEFT over the original model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "X2JFTooimR_t",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2JFTooimR_t",
        "outputId": "c7cb8df6-4b60-491b-9382-99884756e919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absolute percentage improvement of the PEFT model over the original model:\n",
            "rouge1: 15.56%\n",
            "rouge2: 2.17%\n",
            "rougeL: 9.01%\n",
            "rougeLsum: 8.68%\n"
          ]
        }
      ],
      "source": [
        "print(\"Absolute percentage improvement of the PEFT model over the original model:\")\n",
        "\n",
        "for key in peft_model_results:\n",
        "    improvement = peft_model_results[key] - original_model_results[key]\n",
        "    print(f'{key}: {improvement*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "P2yCaFcWmbWh",
      "metadata": {
        "id": "P2yCaFcWmbWh"
      },
      "source": [
        "Now calculate the improvement of PEFT over a full fine-tuned model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "nNLKL9fOmc0p",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNLKL9fOmc0p",
        "outputId": "5ac7d28b-448e-4314-cd4f-34f11d00f587"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absolute percentage improvement of the PEFT model over the instruct model:\n",
            "rouge1: 2.81%\n",
            "rouge2: -1.52%\n",
            "rougeL: -0.43%\n",
            "rougeLsum: -0.50%\n"
          ]
        }
      ],
      "source": [
        "print(\"Absolute percentage improvement of the PEFT model over the instruct model:\")\n",
        "\n",
        "for key in peft_model_results:\n",
        "    improvement = peft_model_results[key] - instruct_model_results[key]\n",
        "    print(f'{key}: {improvement*100:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Tpji7Bi6meQx",
      "metadata": {
        "id": "Tpji7Bi6meQx"
      },
      "source": [
        "You can see a small percentage decrease in the ROUGE metrics vs. full fine-tuned. However, the training requires much less computing and memory resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58819c16",
      "metadata": {
        "id": "58819c16"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5532a6f9ef7c4c64860256251072932e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d6ce7dab7dd45dea2466a897a8a14e2",
              "IPY_MODEL_a4086d034765449db57b24ef1c630e03",
              "IPY_MODEL_74f45dc6318540eb8a3d62c7ad47f569"
            ],
            "layout": "IPY_MODEL_d70194811cb94588a962dafddfb610a1"
          }
        },
        "9d6ce7dab7dd45dea2466a897a8a14e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3f3c1cb97fe4f3a9d1a7b3fe44b8e67",
            "placeholder": "​",
            "style": "IPY_MODEL_f0285d9dbe7240f48c35e3d2a4bd00cb",
            "value": "Map: 100%"
          }
        },
        "a4086d034765449db57b24ef1c630e03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52bebf69b1584849b40749c5f4cb28ed",
            "max": 12460,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afc28a291ddf4193b0f34d75e473857f",
            "value": 12460
          }
        },
        "74f45dc6318540eb8a3d62c7ad47f569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_754a649c43cf4e9285c20ed715306258",
            "placeholder": "​",
            "style": "IPY_MODEL_ed7c636fb5fb4f2a8c73745cf33d5323",
            "value": " 12460/12460 [00:03&lt;00:00, 3215.82 examples/s]"
          }
        },
        "d70194811cb94588a962dafddfb610a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3f3c1cb97fe4f3a9d1a7b3fe44b8e67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0285d9dbe7240f48c35e3d2a4bd00cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52bebf69b1584849b40749c5f4cb28ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afc28a291ddf4193b0f34d75e473857f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "754a649c43cf4e9285c20ed715306258": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed7c636fb5fb4f2a8c73745cf33d5323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26958cdd43b44b4180d9db5f0d8fd00f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9768ca1de2a4221bed18080fa944eb4",
              "IPY_MODEL_5cf8f637718946698a9ad1c37f84045a",
              "IPY_MODEL_b9fea0370e1c4c6a8f5ce8f59e152b0d"
            ],
            "layout": "IPY_MODEL_664fe8697cd64c1d935aee75efbeb7b7"
          }
        },
        "e9768ca1de2a4221bed18080fa944eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5b8459290d64dcc80ae0d15585d9df8",
            "placeholder": "​",
            "style": "IPY_MODEL_bdb1c5af6b8e49bd8b61addacf0b2de2",
            "value": "Map: 100%"
          }
        },
        "5cf8f637718946698a9ad1c37f84045a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a71b8fe4930240a58910040427543ad5",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e847347474b744afaf3e94e2e4e7df03",
            "value": 500
          }
        },
        "b9fea0370e1c4c6a8f5ce8f59e152b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb9affbefa1b4fe48aaba0abe203c518",
            "placeholder": "​",
            "style": "IPY_MODEL_9672a2e06d264c28a1dc755496c4b41f",
            "value": " 500/500 [00:00&lt;00:00, 3220.49 examples/s]"
          }
        },
        "664fe8697cd64c1d935aee75efbeb7b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5b8459290d64dcc80ae0d15585d9df8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdb1c5af6b8e49bd8b61addacf0b2de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a71b8fe4930240a58910040427543ad5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e847347474b744afaf3e94e2e4e7df03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb9affbefa1b4fe48aaba0abe203c518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9672a2e06d264c28a1dc755496c4b41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e87b4377515e4891bb70ae1bfd5d0a69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_203781307b194b10b08f6ac1a72d9c1f",
              "IPY_MODEL_afc1c67ef78040c58e48be5949e0c563",
              "IPY_MODEL_5cddd283ec0b41eb947ef950fc8095b3"
            ],
            "layout": "IPY_MODEL_939c622fdf0741b39cf68d8cf42b61b0"
          }
        },
        "203781307b194b10b08f6ac1a72d9c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87d38c2a23b242c18153203d076d60f3",
            "placeholder": "​",
            "style": "IPY_MODEL_f433e69cca824d5d830012d775d0fd57",
            "value": "Map: 100%"
          }
        },
        "afc1c67ef78040c58e48be5949e0c563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d8a3a4ab248417e996370faba9af58b",
            "max": 1500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e47f089bc174e2fa9fc5d0bcd42a2d8",
            "value": 1500
          }
        },
        "5cddd283ec0b41eb947ef950fc8095b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3433db2503d418a847d3b3bdf138eb6",
            "placeholder": "​",
            "style": "IPY_MODEL_3d4c58b99bcb45ceb0bfb5839389f2a7",
            "value": " 1500/1500 [00:00&lt;00:00, 3164.76 examples/s]"
          }
        },
        "939c622fdf0741b39cf68d8cf42b61b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87d38c2a23b242c18153203d076d60f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f433e69cca824d5d830012d775d0fd57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d8a3a4ab248417e996370faba9af58b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e47f089bc174e2fa9fc5d0bcd42a2d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3433db2503d418a847d3b3bdf138eb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d4c58b99bcb45ceb0bfb5839389f2a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0df2b2052f4c48a1b71e82bdb11c49d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed5cd674bd0a4fccab9c1a32b66b631d",
              "IPY_MODEL_c6368f64fc6d4dd5a39731d49ee46bf6",
              "IPY_MODEL_7131be181fec4e4581bf8a27c8d62cf1"
            ],
            "layout": "IPY_MODEL_bb7e510d39a74009bca93a2d67746ca1"
          }
        },
        "ed5cd674bd0a4fccab9c1a32b66b631d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f42e0ee80fa487badb6f6f319497c65",
            "placeholder": "​",
            "style": "IPY_MODEL_6fd074f5dec84734b2a89ce3e1f25d03",
            "value": "Downloading builder script: "
          }
        },
        "c6368f64fc6d4dd5a39731d49ee46bf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_051cb2fc4508453b97d1ce4e14c689a0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77564d3aaf5a4e60a3250b06f9583871",
            "value": 1
          }
        },
        "7131be181fec4e4581bf8a27c8d62cf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f14419121e114de98470658863061b4b",
            "placeholder": "​",
            "style": "IPY_MODEL_0e58fcf093b64955b86a6cc5923613e8",
            "value": " 6.27k/? [00:00&lt;00:00, 528kB/s]"
          }
        },
        "bb7e510d39a74009bca93a2d67746ca1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f42e0ee80fa487badb6f6f319497c65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fd074f5dec84734b2a89ce3e1f25d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "051cb2fc4508453b97d1ce4e14c689a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "77564d3aaf5a4e60a3250b06f9583871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f14419121e114de98470658863061b4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e58fcf093b64955b86a6cc5923613e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}